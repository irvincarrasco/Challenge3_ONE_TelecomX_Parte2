# üìë Challenge 3 ONE TelecomX Parte 2

## üîç Evaluaci√≥n de Regresi√≥n Log√≠stica

---

* ‚úÖ **Accuracy** : 0.8009
* üéØ **Precision**: 0.6529
* üì° **Recall**   : 0.5365
* ‚öñÔ∏è **F1-score** : 0.5890

**Matriz de Confusi√≥n:**

```
[[1389  160]
 [ 260  301]]
```

**Reporte Completo:**

```
              precision    recall  f1-score   support

           0       0.84      0.90      0.87      1549
           1       0.65      0.54      0.59       561

    accuracy                           0.80      2110
   macro avg       0.75      0.72      0.73      2110
weighted avg       0.79      0.80      0.79      2110
```

---

## üîç Evaluaci√≥n de Random Forest

---

* ‚úÖ **Accuracy** : 0.7820
* üéØ **Precision**: 0.6145
* üì° **Recall**   : 0.4831
* ‚öñÔ∏è **F1-score** : 0.5409

**Matriz de Confusi√≥n:**

```
[[1379  170]
 [ 290  271]]
```

**Reporte Completo:**

```
              precision    recall  f1-score   support

           0       0.83      0.89      0.86      1549
           1       0.61      0.48      0.54       561

    accuracy                           0.78      2110
   macro avg       0.72      0.69      0.70      2110
weighted avg       0.77      0.78      0.77      2110
```

---

## üìä Comparaci√≥n de Modelos

| Modelo              | Accuracy | Precision | Recall | F1-score |
| ------------------- | -------- | --------- | ------ | -------- |
| Regresi√≥n Log√≠stica | 0.8009   | 0.6529    | 0.5365 | 0.5890   |
| Random Forest       | 0.7820   | 0.6145    | 0.4831 | 0.5409   |

---

## üìå An√°lisis Cr√≠tico

* **Mejor desempe√±o:** La **Regresi√≥n Log√≠stica** super√≥ ligeramente al Random Forest en todas las m√©tricas principales, especialmente en **accuracy** (0.80 vs 0.78) y **F1-score** (0.589 vs 0.541).

* **Overfitting/Underfitting:**

  * Ning√∫n modelo presenta un **overfitting severo**, ya que la diferencia entre m√©tricas en clases mayoritaria y minoritaria no es extrema.
  * Sin embargo, ambos modelos muestran **underfitting en la clase positiva (cancelaci√≥n)**, ya que el recall (0.54 en LogReg, 0.48 en RF) indica que muchos clientes cancelados no fueron detectados.
  * Posibles causas: desbalance en los datos (clase negativa m√°s numerosa) y complejidad insuficiente para capturar patrones de cancelaci√≥n.

* **Acciones recomendadas:**

  * Aplicar **t√©cnicas de balanceo** (SMOTE, undersampling, oversampling).
  * Afinar **hiperpar√°metros** en Random Forest para mejorar recall.
  * Considerar modelos m√°s complejos (XGBoost, Gradient Boosting) o ensamblados.

---

## üéØ Conclusi√≥n

* El modelo de **Regresi√≥n Log√≠stica** es el m√°s adecuado en esta primera iteraci√≥n por su mejor balance entre precisi√≥n y recall.
* La clase de **cancelaci√≥n (1)** requiere mayor atenci√≥n, ya que ambos modelos presentan baja sensibilidad en su detecci√≥n.
* Factores clave que deben analizarse en profundidad: caracter√≠sticas relacionadas con la duraci√≥n de la relaci√≥n con el cliente, consumo de servicios y variables demogr√°ficas.

**Estrategia de Retenci√≥n:**

1. Identificar clientes con **alto riesgo de cancelaci√≥n** mediante el modelo de Regresi√≥n Log√≠stica.
2. Implementar campa√±as de **retenci√≥n personalizada** en este segmento.
3. Aplicar **programas de fidelizaci√≥n** para aumentar la permanencia.
4. Continuar mejorando el modelo mediante balanceo de clases y ajuste de hiperpar√°metros.
